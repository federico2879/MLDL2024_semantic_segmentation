{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import Repository"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:25:57.219038Z","iopub.status.busy":"2024-06-11T09:25:57.218641Z","iopub.status.idle":"2024-06-11T09:25:58.837710Z","shell.execute_reply":"2024-06-11T09:25:58.836780Z","shell.execute_reply.started":"2024-06-11T09:25:57.219008Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'MLDL2024_semantic_segmentation'...\n","remote: Enumerating objects: 454, done.\u001b[K\n","remote: Counting objects: 100% (105/105), done.\u001b[K\n","remote: Compressing objects: 100% (100/100), done.\u001b[K\n","remote: Total 454 (delta 55), reused 3 (delta 3), pack-reused 349\u001b[K\n","Receiving objects: 100% (454/454), 220.69 KiB | 3.06 MiB/s, done.\n","Resolving deltas: 100% (262/262), done.\n"]}],"source":["!git clone https://github.com/federico2879/MLDL2024_semantic_segmentation.git"]},{"cell_type":"markdown","metadata":{},"source":["## Import package"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:25:58.840069Z","iopub.status.busy":"2024-06-11T09:25:58.839780Z","iopub.status.idle":"2024-06-11T09:26:18.025576Z","shell.execute_reply":"2024-06-11T09:26:18.024476Z","shell.execute_reply.started":"2024-06-11T09:25:58.840038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m705.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.1)\n","Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (9.5.0)\n","Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m792.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.9.0)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=3e3dbe467f2bd5f823f0722423e90518ec861a09015339c0388ccb33c7f0fa4e\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=3f1571d79bb6a261077fec9d881110441baaf3e8f70d7c8f728a098b08691ef2\n","  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n"]}],"source":["!pip install -U fvcore"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:18.027856Z","iopub.status.busy":"2024-06-11T09:26:18.027090Z","iopub.status.idle":"2024-06-11T09:26:25.087486Z","shell.execute_reply":"2024-06-11T09:26:25.086510Z","shell.execute_reply.started":"2024-06-11T09:26:18.027820Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.transforms.functional import InterpolationMode\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import csv\n","from MLDL2024_semantic_segmentation.datasets.cityscapes import CityScapes\n","from MLDL2024_semantic_segmentation.models.deeplabv2.deeplabv2 import *\n","from MLDL2024_semantic_segmentation.train import * \n","from MLDL2024_semantic_segmentation.utils import *\n","from MLDL2024_semantic_segmentation.models.metrics import * \n","from MLDL2024_semantic_segmentation.models.IOU import * "]},{"cell_type":"markdown","metadata":{},"source":["## Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:25.089314Z","iopub.status.busy":"2024-06-11T09:26:25.088844Z","iopub.status.idle":"2024-06-11T09:26:25.143941Z","shell.execute_reply":"2024-06-11T09:26:25.143084Z","shell.execute_reply.started":"2024-06-11T09:26:25.089278Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","# Setup fixed parameters\n","num_classes = 19\n","num_epochs = 1"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:25.146681Z","iopub.status.busy":"2024-06-11T09:26:25.146372Z","iopub.status.idle":"2024-06-11T09:26:25.158124Z","shell.execute_reply":"2024-06-11T09:26:25.157153Z","shell.execute_reply.started":"2024-06-11T09:26:25.146644Z"},"trusted":true},"outputs":[],"source":["# Transformations\n","transform_image = transforms.Compose([\n","    transforms.Resize((1024, 512)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","transform_target = transforms.Compose([\n","    transforms.Resize((1024, 512), interpolation=InterpolationMode.NEAREST)\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:25.159683Z","iopub.status.busy":"2024-06-11T09:26:25.159329Z","iopub.status.idle":"2024-06-11T09:26:25.411471Z","shell.execute_reply":"2024-06-11T09:26:25.410752Z","shell.execute_reply.started":"2024-06-11T09:26:25.159641Z"},"trusted":true},"outputs":[],"source":["# Create dataloader\n","train_dataset = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', split = 'train', transform = transform_image, label_transform = transform_target)\n","dataloader_train = DataLoader(train_dataset, batch_size=2, shuffle=True)\n","\n","val_dataset = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', split = 'val', transform = transform_image, label_transform = transform_target)\n","dataloader_val = DataLoader(val_dataset, batch_size=2, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Network, Loss, Optimizer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:25.412711Z","iopub.status.busy":"2024-06-11T09:26:25.412468Z","iopub.status.idle":"2024-06-11T09:26:29.427821Z","shell.execute_reply":"2024-06-11T09:26:29.426667Z","shell.execute_reply.started":"2024-06-11T09:26:25.412690Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n","100%|██████████| 171M/171M [00:01<00:00, 157MB/s]  \n"]},{"name":"stdout","output_type":"stream","text":["Deeplab pretraining loading...\n"]}],"source":["# Pretrained\n","pretrained = torchvision.models.resnet101(pretrained=True).to(device)\n","torch.save(pretrained.state_dict(), \"DeepLab_resnet_pretrained_imagenet.pth\")\n","\n","# Inizialization of the model\n","model = get_deeplab_v2().to(device)\n","diz_optim = model.optim_parameters(0.001) # parameters + learning rates\n","\n","#Putting on the 2 gpus\n","model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:29.429278Z","iopub.status.busy":"2024-06-11T09:26:29.428999Z","iopub.status.idle":"2024-06-11T09:26:29.441331Z","shell.execute_reply":"2024-06-11T09:26:29.440362Z","shell.execute_reply.started":"2024-06-11T09:26:29.429254Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n","  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n"]}],"source":["# Define loss and optimizer\n","loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n","optimizer = torch.optim.SGD(diz_optim, momentum=0.9, weight_decay=0.0005)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["meanIOU_tr = np.zeros((num_epochs,1))\n","IOU_tr = np.zeros((num_epochs,num_classes))\n","loss_tr = np.zeros((num_epochs,1))\n","\n","\n","meanIOU_val = np.zeros((num_epochs,1))\n","IOU_val = np.zeros((num_epochs,num_classes))\n","loss_val = np.zeros((num_epochs,1))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:29.442718Z","iopub.status.busy":"2024-06-11T09:26:29.442432Z","iopub.status.idle":"2024-06-11T09:26:29.450666Z","shell.execute_reply":"2024-06-11T09:26:29.449945Z","shell.execute_reply.started":"2024-06-11T09:26:29.442694Z"},"trusted":true},"outputs":[],"source":["# Set the random seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T09:26:29.451998Z","iopub.status.busy":"2024-06-11T09:26:29.451665Z","iopub.status.idle":"2024-06-11T09:44:17.997191Z","shell.execute_reply":"2024-06-11T09:44:17.995807Z","shell.execute_reply.started":"2024-06-11T09:26:29.451973Z"},"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    lr_1x = poly_lr_scheduler(optimizer, 0.001, epoch, lr_decay_iter=1,\n","                      max_iter=num_epochs, power=0.9)\n","    optimizer.param_groups[1]['lr'] = 10*lr_1x\n","    meanIOU_tr[epoch], IOU_tr[epoch,:], loss_tr[epoch] = train(model, optimizer, dataloader_train, loss_fn, num_classes, 0)\n","    meanIOU_val[epoch], IOU_val[epoch,:], loss_val[epoch] = test(model, dataloader_val, loss_fn, num_classes, 0)\n","    print(f\"epoch: {epoch + 1}, Validation IOU: {meanIOU_val[epoch]:.2f}\")\n","\n","    torch.save({\n","        'epoch': epoch,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","        'val_IOU': meanIOU_val[epoch]\n","    },\"checkpoint.pth.tar\")\n","\n","print(f\"Final mIOU: {meanIOU_val[epoch]:.2f}\")\n","print(\"Final IOU classes\")\n","print(IOU_val[epoch,:])\n","\n","flops = Flops(model, 1024, 512)\n","\n","#print(f\"Number of flops?: {flops}\")\n","\n","latency = Latency_FPS(model, 1024, 512)\n","\n","print(f\"Latency: {latency}\")\n","\n","#print(f\"number of parameters: {model.count_params()}\")\n","\n","# Access the actual model being parallelized\n","actual_model = model.module\n","# Count the parameters of the actual model\n","num_params = count_params(actual_model)\n","print(f\"number of parameters: {num_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('meanIOU_tr.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(meanIOU_tr)\n","\n","with open('IOU_tr.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(IOU_tr)\n","\n","with open('loss_tr.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(loss_tr)\n","\n","with open('meanIOU_val.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(meanIOU_val)\n","\n","with open('IOU_val.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(IOU_val)\n","\n","with open('loss_val.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(loss_val)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5006503,"sourceId":8476013,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
