{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8476013,
          "sourceType": "datasetVersion",
          "datasetId": 5006503
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "training_bisenet",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/federico2879/MLDL2024_semantic_segmentation/blob/master/training/training-bisenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/federico2879/MLDL2024_semantic_segmentation.git"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-26T15:22:42.329111Z",
          "iopub.execute_input": "2024-05-26T15:22:42.329704Z",
          "iopub.status.idle": "2024-05-26T15:22:43.969885Z",
          "shell.execute_reply.started": "2024-05-26T15:22:42.32967Z",
          "shell.execute_reply": "2024-05-26T15:22:43.968727Z"
        },
        "trusted": true,
        "id": "ZkSivqu4gVTF",
        "outputId": "25f45487-c2ba-4915-963e-67b6482fa5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'MLDL2024_semantic_segmentation'...\nremote: Enumerating objects: 359, done.\u001b[K\nremote: Counting objects: 100% (138/138), done.\u001b[K\nremote: Compressing objects: 100% (114/114), done.\u001b[K\nremote: Total 359 (delta 74), reused 48 (delta 24), pack-reused 221\u001b[K\nReceiving objects: 100% (359/359), 194.08 KiB | 2.70 MiB/s, done.\nResolving deltas: 100% (199/199), done.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from MLDL2024_semantic_segmentation.datasets.cityscapes import CityScapes\n",
        "from MLDL2024_semantic_segmentation.models.bisenet.build_bisenet import *\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "dTimRLCcgVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "poZOv82xgVTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import gc\n",
        "\n",
        "# Function to clear GPU memory\n",
        "def clear_gpu_memory():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    '''"
      ],
      "metadata": {
        "trusted": true,
        "id": "YfkeQyjkgVTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import time\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "def fast_hist(pred, target, num_classes):\n",
        "    k = (pred >= 0) & (pred < num_classes)\n",
        "    return np.bincount(num_classes * pred[k].astype(int) + target[k], minlength = num_classes**2).reshape(num_classes, num_classes)\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n",
        "\n",
        "def meanIOU(num_clasess, pred, target):\n",
        "  mIOU = 0\n",
        "  for i in range(len(pred)):\n",
        "      hist = fast_hist(pred[i].cpu().numpy(), target[i].cpu().numpy(), num_classes)\n",
        "      IOU = per_class_iou(hist)\n",
        "      mIOU = mIOU + sum(IOU)/num_classes\n",
        "  return mIOU #*100/len(pred)\n",
        "'''"
      ],
      "metadata": {
        "trusted": true,
        "id": "SCR2yExZgVTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U fvcore\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ApxYS2JlgVTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "import time\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "def Flops(model, height, width):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    image = torch.zeros((1, 3, height, width)).to(device)\n",
        "    flops = FlopCountAnalysis(model, image)\n",
        "  flops_CT = flop_count_table(flops)\n",
        "  print(flops_CT)\n",
        "  return flops, flops_CT\n",
        "\n",
        "def Latency_FPS(model, height, width):\n",
        "  image = torch.rand((1, 3, height, width)).to(device)\n",
        "  iterations = 1000\n",
        "  latency = []\n",
        "  FPS = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i in range(iterations):\n",
        "      start = time.time()\n",
        "\n",
        "      output = model(image)\n",
        "\n",
        "      end = time.time()\n",
        "      ltc_i = end-start\n",
        "      latency.append(ltc_i)\n",
        "      FPS_i = 1/ltc_i\n",
        "      FPS.append(FPS_i)\n",
        "\n",
        "  meanLatency = statistics.mean(latency)*1000\n",
        "  stdLatency = statistics.stdev(latency)*1000\n",
        "  meanFPS = statistics.mean(FPS)*1000\n",
        "  stdFPS = statistics.stdev(FPS)*1000\n",
        "  return meanLatency, stdLatency, meanFPS, stdFPS\n",
        "  '''"
      ],
      "metadata": {
        "trusted": true,
        "id": "GYc09T-5gVTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from MLDL2024_semantic_segmentation.models.metrics import metric_pip_install\n",
        "\n",
        "metric_pip_install()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "mhh-NHlcgVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "clear_memory_every = 10\n",
        "\n",
        "def train(model, optimizer, train_loader, loss_fn):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total_iou = 0\n",
        "    total_images = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "        #print(f'batch id: {batch_idx}')\n",
        "        #print(f'(inputs, targets): {(inputs.size(), targets.size())}')\n",
        "        first_image = inputs[0]\n",
        "\n",
        "        # Stampiamo le dimensioni della prima immagine nel batch\n",
        "        #print(\"Dimensioni della prima immagine nel batch:\", first_image.size())\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        outputs =  model(inputs)\n",
        "\n",
        "        #Ridimensioning tensor\n",
        "        targets = targets.squeeze(dim=1)\n",
        "        #print(f'targets size: {targets.size()}')\n",
        "\n",
        "        targets = targets.long()\n",
        "\n",
        "        loss = loss_fn(outputs[0], targets)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad() # reset gradients of parameters\n",
        "        loss.backward()  # backpropagate the prediction loss\n",
        "        optimizer.step() # update model\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs[0].max(1)\n",
        "        #print(f'predicted: {predicted}')\n",
        "        iou = meanIOU(outputs[0].size()[1], predicted, targets) #sum of meanIOU over classes di tutte le immagini nel batch\n",
        "        total_iou += iou.sum().item()  #somma di tytte le singole iou calcolate in precedenza\n",
        "        total_images += len(targets)\n",
        "\n",
        "        # Clear GPU memory periodically\n",
        "        if batch_idx % clear_memory_every == 0:\n",
        "            clear_gpu_memory()\n",
        "\n",
        "    result= total_iou/total_images\n",
        "    return result\n",
        "\n",
        "def test(model, test_loader, loss_fn):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total_images = 0\n",
        "    total_iou = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "            #Ridimensioning tensor+\n",
        "\n",
        "            targets = targets.squeeze(dim=1)\n",
        "\n",
        "            #print(f'targets size: {targets.size()}')\n",
        "\n",
        "            targets = targets.long()\n",
        "            #print(f'targets type: {targets.type()}')\n",
        "            #print(f'targets size: {targets.size()}')\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            #print(f'predicted: {predicted}')\n",
        "            iou = meanIOU(outputs.size()[1], predicted, targets) #sum of meanIOU over classes di tutte le immagini nel batch\n",
        "            #total += targets.size(0)\n",
        "            #correct += predicted.eq(targets).sum().item()\n",
        "            total_iou += iou.sum().item()  #somma di tytte le singole iou calcolate in precedenza\n",
        "\n",
        "            #print(f'len di targets (=batch_size?): {len(targets)}')\n",
        "            total_images += len(targets)\n",
        "\n",
        "            # Clear GPU memory periodically\n",
        "            if batch_idx % clear_memory_every == 0:\n",
        "                clear_gpu_memory()\n",
        "\n",
        "    result= total_iou/total_images\n",
        "    #test_loss = test_loss / len(test_loader)\n",
        "    #test_accuracy = 100. * correct / total\n",
        "    return result\n",
        "'''"
      ],
      "metadata": {
        "trusted": true,
        "id": "Bzil68nEgVTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from MLDL2024_semantic_segmentation.models.metrics import *\n",
        "from MLDL2024_semantic_segmentation.train import *"
      ],
      "metadata": {
        "trusted": true,
        "id": "uCZ3cX19gVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup fixed parameters\n",
        "num_epochs = 1\n",
        "num_classes = 19"
      ],
      "metadata": {
        "trusted": true,
        "id": "1xQKHQ63gVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "transform_image = transforms.Compose([\n",
        "    transforms.Resize((1024, 512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_target = transforms.Compose([\n",
        "    transforms.Resize((1024, 512)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataloader\n",
        "dataset_train = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', split = 'train', transform = transform_image, label_transform = transform_target)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
        "\n",
        "dataset_val = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', split = 'val', transform = transform_image, label_transform = transform_target)\n",
        "dataloader_val = DataLoader(dataset_train, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zhlYdzgGgVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inizialization of the model\n",
        "model = BiSeNet(num_classes=num_classes, context_path=\"resnet18\").to(device)\n",
        "model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2S7AJWT0gVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZxD5yx3YgVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4u6b7KqegVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "mIOU = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, optimizer, dataloader_train, loss_fn, 10)\n",
        "    mIOU = test(model, dataloader_val, loss_fn, 10)\n",
        "    print(f\"epoch: {epoch}, Validation IOU: {mIOU:.2f}\")\n",
        "\n",
        "    '''\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'val_IOU': val_IOU\n",
        "    },\"checkpoint.pth.tar\")\n",
        "    '''\n",
        "print(f\"Final mIOU: {mIOU:.2f}\")\n",
        "\n",
        "flops = Flops(model, 1024, 512)\n",
        "\n",
        "print(f\"Number of flops?: {flops}\")\n",
        "\n",
        "latency = Latency_FPS(model, 1024, 512)\n",
        "\n",
        "print(f\"Latency: {latency}\")\n",
        "\n",
        "print(f\"number of parameters: {model.count_params()}\")\n",
        "\n",
        "\n",
        "\n",
        "# Access the actual model being parallelized\n",
        "actual_model = model.module\n",
        "# Count the parameters of the actual model\n",
        "num_params = count_params(actual_model)\n",
        "print(f\"number of parameters: {num_params}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "KWIYCskigVTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "2-CTLqkPgVTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}