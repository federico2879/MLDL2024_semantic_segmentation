{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8476013,"sourceType":"datasetVersion","datasetId":5006503}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import repository","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/federico2879/MLDL2024_semantic_segmentation.git","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:41.283200Z","iopub.execute_input":"2024-06-04T12:55:41.283645Z","iopub.status.idle":"2024-06-04T12:55:42.369963Z","shell.execute_reply.started":"2024-06-04T12:55:41.283615Z","shell.execute_reply":"2024-06-04T12:55:42.368809Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"fatal: destination path 'MLDL2024_semantic_segmentation' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import package","metadata":{}},{"cell_type":"code","source":"!pip install -U fvcore","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:42.372525Z","iopub.execute_input":"2024-06-04T12:55:42.372875Z","iopub.status.idle":"2024-06-04T12:55:56.456528Z","shell.execute_reply.started":"2024-06-04T12:55:42.372845Z","shell.execute_reply":"2024-06-04T12:55:56.455451Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fvcore in /opt/conda/lib/python3.10/site-packages (0.1.5.post20221221)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore) (1.26.4)\nRequirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.8)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore) (4.66.4)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore) (2.4.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore) (9.5.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.9.0)\nRequirement already satisfied: iopath>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from fvcore) (0.1.10)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (4.9.0)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore) (2.8.2)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n#from MLDL2024_semantic_segmentation.datasets.cityscapes import CityScapes\n#from MLDL2024_semantic_segmentation.models.bisenet.build_contextpath import *\nfrom MLDL2024_semantic_segmentation.models.bisenet.build_bisenet import *\nfrom MLDL2024_semantic_segmentation.train import *\nfrom MLDL2024_semantic_segmentation.utils import *\nfrom MLDL2024_semantic_segmentation.models.metrics import *\n#from MLDL2024_semantic_segmentation.models.IOU import * ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.458150Z","iopub.execute_input":"2024-06-04T12:55:56.458509Z","iopub.status.idle":"2024-06-04T12:55:56.465912Z","shell.execute_reply.started":"2024-06-04T12:55:56.458477Z","shell.execute_reply":"2024-06-04T12:55:56.464806Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# Setup device agnostic code\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\n\n# Setup fixed parameters\nnum_classes = 19\nnum_epochs = 1","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.468429Z","iopub.execute_input":"2024-06-04T12:55:56.468759Z","iopub.status.idle":"2024-06-04T12:55:56.479471Z","shell.execute_reply.started":"2024-06-04T12:55:56.468724Z","shell.execute_reply":"2024-06-04T12:55:56.478442Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport os\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torch\n\nclass CityScapes(Dataset):\n    def __init__(self, root_dir, split = 'train', transform=None, label_transform=None):\n        super(CityScapes, self).__init__()\n        self.root_dir = root_dir\n        self.image_dir = os.path.join(root_dir, 'images', split)\n        self.label_dir = os.path.join(root_dir, 'gtFine', split)\n        self.transform = transform\n        self.label_transform = label_transform\n        self.images = os.listdir(self.image_dir)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.image_dir, img_name)\n        label_name = img_name.replace('leftImg8bit', 'gtFine_labelTrainIds')\n        label_path = os.path.join(self.label_dir, label_name)\n        \n        image = Image.open(img_path).convert('RGB')\n        label = Image.open(label_path)\n        #label = torch.cat([label] * 3, dim=0)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.label_transform is not None:\n            label = self.label_transform(label)\n\n        label_array = np.array(label) / 255.0\n        class_indices = (label_array * 19).astype(np.int)\n        label = torch.tensor(class_indices)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.480892Z","iopub.execute_input":"2024-06-04T12:55:56.481911Z","iopub.status.idle":"2024-06-04T12:55:56.494775Z","shell.execute_reply.started":"2024-06-04T12:55:56.481854Z","shell.execute_reply":"2024-06-04T12:55:56.493678Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"# Transformations\ntransform_image = transforms.Compose([\n    transforms.Resize((1024, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\ntransform_target = transforms.Compose([\n    transforms.Resize((1024, 512))\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.495959Z","iopub.execute_input":"2024-06-04T12:55:56.496304Z","iopub.status.idle":"2024-06-04T12:55:56.506330Z","shell.execute_reply.started":"2024-06-04T12:55:56.496268Z","shell.execute_reply":"2024-06-04T12:55:56.505315Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create dataloader\ntrain_dataset = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', \n                           split = 'train', transform = transform_image, \n                           label_transform = transform_target)\ndataloader_train = DataLoader(train_dataset, batch_size=4, shuffle=True)\n\nval_dataset = CityScapes('/kaggle/input/cityscapes/Cityscapes/Cityspaces', \n                         split = 'val', transform = transform_image, \n                         label_transform = transform_target)\ndataloader_val = DataLoader(val_dataset, batch_size=4, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.507748Z","iopub.execute_input":"2024-06-04T12:55:56.508175Z","iopub.status.idle":"2024-06-04T12:55:56.521183Z","shell.execute_reply.started":"2024-06-04T12:55:56.508104Z","shell.execute_reply":"2024-06-04T12:55:56.520267Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Network, Loss, Optimizer","metadata":{}},{"cell_type":"code","source":"# Inizialization of the model\nmodel = BiSeNet(num_classes=num_classes, context_path=\"resnet18\").to(device)\n\n#Putting on the 2 gpus\nmodel = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:56.522525Z","iopub.execute_input":"2024-06-04T12:55:56.522875Z","iopub.status.idle":"2024-06-04T12:55:58.277927Z","shell.execute_reply.started":"2024-06-04T12:55:56.522848Z","shell.execute_reply":"2024-06-04T12:55:58.275849Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Inizialization of the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBiSeNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Putting on the 2 gpus\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(model, device_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"# Define loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=2.5e-2,\n                            momentum=0.9,weight_decay=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:58.279139Z","iopub.status.idle":"2024-06-04T12:55:58.279543Z","shell.execute_reply.started":"2024-06-04T12:55:58.279343Z","shell.execute_reply":"2024-06-04T12:55:58.279359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef fast_hist(pred, target, num_classes):\n    k = (pred >= 0) & (pred < num_classes)\n    return np.bincount(num_classes * pred[k].astype(int) + target[k], minlength = num_classes**2).reshape(num_classes, num_classes)\n\ndef per_class_iou(hist):\n    epsilon = 1e-5\n    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)\n\ndef meanIOU(num_classes, pred, target):\n  mIOU = 0\n  IOU_classes = np.zeros([1,num_classes])  \n  for i in range(len(pred)):    \n      hist = fast_hist(pred[i].cpu().numpy(), target[i].cpu().numpy(), num_classes)\n      IOU = per_class_iou(hist)\n      print(IOU)\n      IOU_classes = IOU_classes + IOU\n      print(IOU_classes)\n      mIOU = mIOU + sum(IOU)/num_classes \n  return mIOU, IOU_classes ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:58.281070Z","iopub.status.idle":"2024-06-04T12:55:58.281576Z","shell.execute_reply.started":"2024-06-04T12:55:58.281319Z","shell.execute_reply":"2024-06-04T12:55:58.281340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport gc\nimport numpy as np\nfrom MLDL2024_semantic_segmentation.models.IOU import meanIOU\n#from MLDL2024_semantic_segmentation.models.metrics import fast_hist\n#from MLDL2024_semantic_segmentation.models.metrics import per_class_iou\n\n\n# Function to clear GPU memory\ndef clear_gpu_memory():\n    torch.cuda.empty_cache()\n    gc.collect()\n\ndef train(model, optimizer, train_loader, loss_fn, num_classes, clear_memory_every):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total_iou = 0\n    total_iou_cl = np.zeros([1,num_classes])\n    total_images = 0\n\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n\n        inputs, targets = inputs.cuda(), targets.cuda()\n\n        # Compute prediction and loss\n        outputs =  model(inputs)\n       \n        #Ridimensioning tensor\n        #print(targets)\n        targets = targets.squeeze(dim=1)\n        #print(f'targets size: {targets.size()}')\n\n        targets = targets.long()\n\n        loss = loss_fn(outputs[0], targets)\n\n        # Backpropagation\n        optimizer.zero_grad() # reset gradients of parameters\n        loss.backward()  # backpropagate the prediction loss\n        optimizer.step() # update model\n\n        #running_loss += loss.item()\n        _, predicted = outputs[0].max(1)\n        iou, iou_cl = meanIOU(num_classes, predicted, targets) #sum of meanIOU over classes di tutte le immagini nel batch\n        total_iou += iou\n        total_iou_cl += iou_cl\n        total_images += len(targets)\n        print(total_iou)\n        print(total_iou_cl)\n        print('######')\n        \n        # Clear GPU memory periodically\n        if clear_memory_every!=0 and batch_idx % clear_memory_every == 0:\n            clear_gpu_memory()\n\n    miou = total_iou/total_images\n    iou_class = total_iou_cl/total_images\n    return miou, iou_class\n\ndef test(model, test_loader, loss_fn, num_clasess, clear_memory_every):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    total_images = 0\n    total_iou = 0\n    total_iou_cl = np.zeros([1,num_classes])\n    \n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(test_loader):\n            inputs, targets = inputs.cuda(), targets.cuda()\n            outputs = model(inputs)\n            \n            #Ridimensioning tensor\n            targets = targets.squeeze(dim=1)\n            targets = targets.long()\n            \n            loss = loss_fn(outputs, targets)\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            \n            iou, iou_cl = meanIOU(num_classes, predicted, targets) #sum of meanIOU over classes di tutte le immagini nel batch\n            total_iou += iou\n            total_iou_cl += iou_cl\n            total_images += len(targets)\n            \n            # Clear GPU memory periodically\n            if clear_memory_every!=0 and batch_idx % clear_memory_every == 0:\n                clear_gpu_memory()\n\n    miou = total_iou/total_images\n    iou_class = total_iou_cl/total_images\n    return miou, iou_class","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:58.283101Z","iopub.status.idle":"2024-06-04T12:55:58.283520Z","shell.execute_reply.started":"2024-06-04T12:55:58.283317Z","shell.execute_reply":"2024-06-04T12:55:58.283334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Set the random seeds\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:58.284800Z","iopub.status.idle":"2024-06-04T12:55:58.285201Z","shell.execute_reply.started":"2024-06-04T12:55:58.285014Z","shell.execute_reply":"2024-06-04T12:55:58.285031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    #poly_lr_scheduler(optimizer, 2.5e-2, epoch, lr_decay_iter=1,\n    #                  max_iter=num_epochs, power=0.9)\n    train(model, optimizer, dataloader_train, loss_fn, 19, 0)\n    val_mIOU,_ = test(model, dataloader_val, loss_fn, 19, 0)\n    print(f\"epoch: {epoch}, Validation IOU: {val_mIOU:.2f}\")\n\n    torch.save({\n        'epoch': epoch + 1,\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'val_IOU': val_mIOU\n    },\"checkpoint.pth.tar\")\n\nprint(f\"Final mIOU: {val_mIOU:.2f}\")\n\nflops = Flops(model, 1024, 512, device)\n\nprint(f\"Number of flops?: {flops}\")\n\nlatency = Latency_FPS(model, 1024, 512, device)\n\nprint(f\"Latency: {latency}\")\n\n#print(f\"number of parameters: {model.count_params()}\")\n\n# Access the actual model being parallelized\nactual_model = model.module\n# Count the parameters of the actual model\nnum_params = count_params(actual_model)\nprint(f\"number of parameters: {num_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T12:55:58.287080Z","iopub.status.idle":"2024-06-04T12:55:58.287581Z","shell.execute_reply.started":"2024-06-04T12:55:58.287321Z","shell.execute_reply":"2024-06-04T12:55:58.287341Z"},"trusted":true},"execution_count":null,"outputs":[]}]}